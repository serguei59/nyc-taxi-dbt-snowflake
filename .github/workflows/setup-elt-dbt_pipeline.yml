name: Full ETL + dbt Pipeline

on:
  push:
    branches:
      - dev
      - main
  workflow_dispatch:

jobs:

  # üîê Step 0: Get Snowflake OAuth Token
  run-snowflake-sql:
    runs-on: ubuntu-latest
    env:
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_USER: ${{ secrets.SNOWFLAKE_USER }}
      SNOWFLAKE_ROLE: ${{ secrets.SNOWFLAKE_ROLE }}
      SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
      SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
      SNOWFLAKE_OAUTH_CLIENT_ID: ${{ secrets.SNOWFLAKE_OAUTH_CLIENT_ID }}
      SNOWFLAKE_OAUTH_CLIENT_SECRET: ${{ secrets.SNOWFLAKE_OAUTH_CLIENT_SECRET }}
    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: "3.12"

      - name: Install dependencies
        run: |
          python3 -m pip install --upgrade pip
          pip install requests jq

          - name: Generate OAuth Token & Run SQL
          id: run_sql
          run: |
            echo "Requesting OAuth token..."
            TOKEN=$(python3 <<EOF
          import requests, os, json
        
          url = f"https://{os.environ['SNOWFLAKE_ACCOUNT']}.snowflakecomputing.com/session/v1/login-request?warehouse={os.environ['SNOWFLAKE_WAREHOUSE']}&database={os.environ['SNOWFLAKE_DATABASE']}&schema={os.environ['SNOWFLAKE_SCHEMA']}"
          payload = {
            "data": {
                "CLIENT_ID": os.environ['SNOWFLAKE_OAUTH_CLIENT_ID'],
                "CLIENT_SECRET": os.environ['SNOWFLAKE_OAUTH_CLIENT_SECRET']
            }
          }
        
          resp = requests.post(url, json=payload)
          resp.raise_for_status()
          print(resp.json()['data']['TOKEN'])
          EOF
            )
            echo "Token obtained: $TOKEN"
        
      - name: Execute SQL via REST API
        run: |
          LOG_FILE=checks/logs/snowflake_setup_rest.log
          mkdir -p checks/logs
          SQL_FILE="extract/sql/cleaninstall.sql"
          SQL_CONTENT=$(jq -Rs . < "$SQL_FILE")  # Convert SQL to JSON string
          
          echo "üîπ Sending SQL to Snowflake..."
          RESPONSE=$(curl -s -X POST "https://${{ secrets.SNOWFLAKE_ACCOUNT }}.snowflakecomputing.com/api/v2/statements" \
            -H "Authorization: Bearer ${{ steps.get_token.outputs.token }}" \
            -H "Content-Type: application/json" \
            -d "{\"statement\":$SQL_CONTENT}" )

          echo "$RESPONSE" > "$LOG_FILE"
          echo "üîπ Response logged to $LOG_FILE"

          # Check for errors in response
          ERROR=$(echo "$RESPONSE" | jq -r '.message // empty')
          if [ -n "$ERROR" ]; then
              echo "‚ùå Snowflake returned an error: $ERROR"
              cat "$LOG_FILE"
              exit 1
          fi

          echo "‚úÖ SQL executed successfully."
      - name: Upload all logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: snowflake-logs
          path: checks/logs/         
         
  # üöÄ Step 2: Python ETL
  python_etl:
    name: Run Python ETL (Download + Ingest)
    runs-on: ubuntu-latest
    needs: run-snowflake-sql
    env:
      SNOWFLAKE_USER: DBT
      SNOWFLAKE_PASSWORD: ${{ secrets.DBT_PASSWORD }}
      SNOWFLAKE_ACCOUNT: ${{ secrets.SNOWFLAKE_ACCOUNT }}
      SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
      SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}
      SNOWFLAKE_ROLE: TRANSFORM

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt

      - name: Ensure data & logs folders exist
        run: |
          mkdir -p extract/data
          mkdir -p checks/logs

      - name: Pre-ingestion checks
        run: |
          echo "Running pre-ingestion checks..."
          python checks/pre_ingestion_check.py >> checks/logs/pre_ingestion_check.log 2>&1 \
            || { echo "Pre-ingestion checks failed. See checks/logs/pre_ingestion_check.log"; exit 1; }

      - name: Download Parquet files
        run: |
          echo "Downloading Parquet files..."
          python extract/download_parquet.py >> checks/logs/download_parquet.log 2>&1 \
            || { echo "Parquet download failed. See checks/logs/download_parquet.log"; exit 1; }

      - name: Ingest to Snowflake
        run: |
          echo "Running merge_dynamic ingestion..."
          python load/merge_dynamic.py >> checks/logs/merge_dynamic.log 2>&1 \
            || { echo "ETL ingestion failed. See checks/logs/merge_dynamic.log"; exit 1; }

  # üß© Step 3: dbt Transformations & Docs
  dbt:
    name: Run dbt Pipeline
    runs-on: ubuntu-latest
    needs: python_etl
    env:
      DBT_PASSWORD: ${{ secrets.DBT_PASSWORD }}
      SNOWFLAKE_WAREHOUSE: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
      SNOWFLAKE_DATABASE: ${{ secrets.SNOWFLAKE_DATABASE }}
      SNOWFLAKE_SCHEMA: ${{ secrets.SNOWFLAKE_SCHEMA }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v3

      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: 3.11

      - name: Install dbt and dependencies
        run: |
          python -m pip install --upgrade pip
          pip install dbt-snowflake dbt-core pandas snowflake-connector-python

      - name: Create dbt profiles.yml
        run: |
          mkdir -p ~/.dbt
          cat <<EOF > ~/.dbt/profiles.yml
          nyc_taxi_dbt_snowflake:
            target: dev
            outputs:
              dev:
                type: snowflake
                user: DBT
                password: ${{ secrets.DBT_PASSWORD }}
                role: TRANSFORM
                warehouse: ${{ secrets.SNOWFLAKE_WAREHOUSE }}
                database: ${{ secrets.SNOWFLAKE_DATABASE }}
                schema: ${{ secrets.SNOWFLAKE_SCHEMA }}
                threads: 1
                client_session_keep_alive: False
          EOF

      - name: Run dbt
        working-directory: ./nyc_taxi_dbt_snowflake
        run: |
          set -e
          echo "üì¶ Installing dbt dependencies..."
          dbt deps --profiles-dir ~/.dbt

          echo "üíæ Refreshing dbt seeds..."
          dbt seed --full-refresh --profiles-dir ~/.dbt

          echo "‚öôÔ∏è Running dbt transformations..."
          dbt run --profiles-dir ~/.dbt

          echo "Running dbt tests..."
          dbt test --profiles-dir ~/.dbt

          echo "Generating dbt docs..."
          dbt docs generate --profiles-dir ~/.dbt

          echo "Saving dbt docs artifacts..."
          mkdir -p ../artifacts/dbt_docs
          cp -r target ../artifacts/dbt_docs

          echo "Copying dbt docs to GitHub Pages folder..."
          mkdir -p ../../docs/dbt_docs
          cp -r target/* ../../docs/dbt_docs/

      - name: Commit & push dbt docs for GitHub Pages
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"
          git add docs/dbt_docs
          git commit -m "Update dbt docs [ci skip]" || echo "No changes to commit"
          git push origin dev
