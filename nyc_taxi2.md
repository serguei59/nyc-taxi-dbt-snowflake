# Brief Projet Data Engineering - Formation Simplon
## Pipeline NYC Taxi : Analyse de Donn√©es Massives avec Snowflake

---

## üìã Contexte du Projet

### üéØ Objectif P√©dagogique
Ma√Ætriser la construction d'un pipeline de donn√©es professionnel en traitant des donn√©es r√©elles volumineuses de NYC Taxi.

### üìä Dataset : NYC Taxi Trip Data
- **Volume** : ~40 millions de trajets (ann√©e 2024 + d√©but 2025)
- **Taille** : ~8 GB de donn√©es compress√©es
- **Source** : [NYC Taxi & Limousine Commission](https://www.nyc.gov/site/tlc/about/tlc-trip-record-data.page)
- **Format** : Fichiers Parquet mensuels
- **Exemple de lien** : https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2025-01.parquet

### üéì Comp√©tences Vis√©es
- Ingestion de donn√©es depuis sources externes
- Architecture de data warehouse (RAW ‚Üí STAGING ‚Üí FINAL)
- Nettoyage et transformation de donn√©es
- Documentation et tests de qualit√©
- (Option) Orchestration de pipelines

### üèóÔ∏è Architecture du Data Warehouse
```
üìÅ Fichiers Parquet ‚Üí RAW ‚Üí STAGING ‚Üí FINAL
                      ‚Üì        ‚Üì         ‚Üì
               Donn√©es brutes ‚Üí Nettoyage ‚Üí Tables analytiques
```

#### Sch√©mas Snowflake Requis
1. **RAW** : Tables sources (donn√©es brutes import√©es)
2. **STAGING** : Tables de nettoyage et transformation
3. **FINAL** : Tables finales pour analyse et dataviz

---

## üìö PARTIE 1 : TRONC COMMUN (OBLIGATOIRE)

### ‚úÖ 1.1 Configuration Snowflake

**Cr√©er l'infrastructure de base :**

**Warehouse (ressource de calcul) :**
- Nom : `NYC_TAXI_WH`
- Taille : MEDIUM (ajustable selon vos cr√©dits)
- Auto-suspend : 60 secondes (√©conomise les cr√©dits)

**Base de donn√©es :**
- Nom : `NYC_TAXI_DB`

**Sch√©mas √† cr√©er :**
- `RAW` : Pour stocker les donn√©es brutes import√©es
- `STAGING` : Pour les donn√©es nettoy√©es et transform√©es
- `FINAL` : Pour les tables finales d'analyse

### ‚úÖ 1.2 Chargement des Donn√©es (2024-2025)
**Objectif** : Charger tous les mois de janvier 2024 √† aujourd'hui

**Deux options de chargement possibles :**

**Option A : Via Snowflake directement (recommand√©)**
- Utiliser les stages externes de Snowflake
- Charger directement depuis l'URL source

**Option B : Via script Python**
- T√©l√©charger les fichiers en local puis charger
- Format des fichiers : `yellow_tripdata_YYYY-MM.parquet`
- URL de base : `https://d37ci6vzurychx.cloudfront.net/trip-data/`
- Exemple : `yellow_tripdata_2024-01.parquet`, `yellow_tripdata_2024-02.parquet`, etc.

**Table RAW √† cr√©er :**
- Nom : `RAW.yellow_taxi_trips`
- Contient : Toutes les donn√©es brutes sans modification
- Colonnes principales : dates pickup/dropoff, distances, montants, zones, etc.

### ‚úÖ 1.3 Analyse et Nettoyage des Donn√©es
**Probl√®mes identifi√©s dans les donn√©es** :
- 15.54% de valeurs manquantes
- 4.15% de montants n√©gatifs
- 2.62% de trajets avec distance z√©ro
- Valeurs extr√™mes aberrantes (distance > 1000 miles)

**Actions de nettoyage requises** :
1. Filtrer les montants n√©gatifs
2. Exclure les trajets avec dates incoh√©rentes
3. G√©rer les valeurs manquantes
4. Supprimer les outliers extr√™mes

---

### ‚úÖ 1.4 Transformations de Base

#### Tables √† cr√©er dans STAGING :

**Table principale nettoy√©e :**
- Nom : `STAGING.clean_trips`
- Source : `RAW.yellow_taxi_trips`
- Filtres √† appliquer :
  - √âliminer les montants n√©gatifs (fare_amount, total_amount)
  - Garder seulement les trajets avec pickup < dropoff
  - Filtrer les distances entre 0.1 et 100 miles
  - Exclure les zones NULL (PULocationID, DOLocationID)

**Enrichissements √† ajouter :**
- Calcul de la dur√©e du trajet (en minutes)
- Extraction des dimensions temporelles (heure, jour, mois)
- Calcul de la vitesse moyenne
- Calcul du pourcentage de pourboire

#### Tables √† cr√©er dans FINAL :

**Table de r√©sum√© quotidien :**
- Nom : `FINAL.daily_summary`
- M√©triques par jour : nombre de trajets, distance moyenne, revenus totaux
- Groupement par date de pickup

**Table d'analyse par zone :**
- Nom : `FINAL.zone_analysis`
- M√©triques par zone de d√©part : volume, revenus moyens, popularit√©

**Table des patterns horaires :**
- Nom : `FINAL.hourly_patterns`
- M√©triques par heure : demande, revenus, vitesse moyenne

---

## üöÄ PARTIE 2 : OPTIONS AVANC√âES (Optionnel)

### üåü Option A : Orchestration avec Airflow/Dagster

**üì∫ Ressource recommand√©e** : [Tutorial Airflow NYC Taxi](https://www.youtube.com/watch?v=OLXkGB7krGo&t=518s)

#### Qu'est-ce qu'Airflow ?
Airflow est un outil d'orchestration qui permet d'automatiser et de planifier vos pipelines de donn√©es. Pour ce projet, vous cr√©erez un DAG (Directed Acyclic Graph) qui :

- **T√©l√©charge automatiquement** les nouvelles donn√©es chaque mois
- **Charge les donn√©es** dans Snowflake
- **Ex√©cute les transformations** SQL
- **Valide la qualit√©** des donn√©es
- **Envoie des notifications** en cas d'erreur

#### Avantages d'Airflow :
- Interface web pour monitorer les pipelines
- Gestion des erreurs et reprises automatiques
- Planification flexible (quotidien, mensuel, etc.)
- Int√©gration native avec Snowflake

### üåü Option B : Orchestration avec GitHub Actions

#### Qu'est-ce que GitHub Actions ?
GitHub Actions permet d'automatiser vos workflows directement depuis votre repository Git. C'est une alternative gratuite et simple √† Airflow.

#### Fonctionnalit√©s du pipeline :
- **D√©clenchement automatique** : Chaque 1er du mois ou manuellement
- **Environnement contr√¥l√©** : Utilise Ubuntu avec Python
- **Secrets s√©curis√©s** : Identifiants Snowflake stock√©s de mani√®re s√©curis√©e
- **Notifications** : Succ√®s/√©chec visible dans GitHub

#### Id√©al pour :
- Projets √©tudiants (gratuit)
- Simplicit√© de mise en place
- Int√©gration avec votre code versioning

### üåü Option C : Transformation avec DBT Core

**üì∫ Ressources recommand√©es** :
- [DBT Core vs DBT Cloud](https://www.youtube.com/watch?v=ZbLzOgAMAwk)
- [DBT + Snowflake Guide](https://dipikajiandani.medium.com/dbt-snowflake-2831681b67f9)

#### Qu'est-ce que DBT ?
DBT (Data Build Tool) est l'outil moderne pour transformer les donn√©es dans votre data warehouse. Il vous permet de :

- **√âcrire des transformations** en SQL pur
- **Tester automatiquement** la qualit√© des donn√©es
- **Documenter** vos mod√®les automatiquement
- **Versionner** vos transformations avec Git

#### Structure DBT pour ce projet :

**Mod√®les Staging (dossier staging/) :**
- `stg_yellow_taxi_trips.sql` : Nettoyage des donn√©es brutes
  - Filtrage des valeurs aberrantes
  - Standardisation des formats
  - Tests de qualit√© int√©gr√©s

**Mod√®les Intermediate (dossier intermediate/) :**
- `int_trip_metrics.sql` : Enrichissement des donn√©es
  - Ajout de cat√©gories (distance, p√©riode temporelle)
  - Calcul de m√©triques (vitesse, pourboires)
  - Dimensions business cr√©√©es

**Mod√®les Marts (dossier marts/) :**
- `fact_trips.sql` : Table de faits principale
- `daily_summary.sql` : R√©sum√©s quotidiens
- `zone_analysis.sql` : Analyses par zone g√©ographique
- `hourly_patterns.sql` : Patterns de demande horaire

#### Avantages de DBT :
- **Tests int√©gr√©s** : Validation automatique de la qualit√©
- **Documentation auto-g√©n√©r√©e** : Site web avec description des tables
- **Lignage des donn√©es** : Visualisation des d√©pendances entre tables
- **Modularit√©** : R√©utilisation des transformations

### üåü Option D : Architecture ELT Moderne

**üìñ Ressource recommand√©e** : [Modern ELT Architecture](https://mayursurani.medium.com/modern-elt-with-dbt-snowflake-and-aws-building-modular-testable-and-governed-data-pipeline-cda2616ad96a)

#### Comprendre l'approche ELT :
- **Extract** : R√©cup√©ration des donn√©es depuis les sources (NYC Open Data)
- **Load** : Chargement direct dans Snowflake (sch√©ma RAW)
- **Transform** : Transformations SQL dans Snowflake (STAGING ‚Üí FINAL)

#### Avantages de l'ELT avec Snowflake :
- Utilisation de la puissance de calcul de Snowflake
- Pas de serveur ETL externe n√©cessaire
- Scalabilit√© automatique selon les besoins
- Co√ªt optimis√© (paiement √† l'usage)

#### Principes de Gouvernance des Donn√©es :
- **Data Lineage** : Tracer l'origine et les transformations de chaque donn√©e
- **Data Quality** : Tests automatis√©s √† chaque √©tape
- **Data Catalog** : Documentation automatique des tables et colonnes
- **Data Security** : Contr√¥les d'acc√®s par sch√©ma et r√¥le

### üåü Option E : Analyses Avanc√©es et DataViz

#### Dashboards √† Cr√©er :
1. **Monitoring Op√©rationnel**
   - KPIs en temps r√©el (trajets, revenus)
   - Heatmaps g√©ographiques des zones actives
   - Alertes sur les anomalies de trafic

2. **Analyses Business**
   - ROI par zone et p√©riode
   - Optimisation de la flotte de taxis
   - Pr√©diction de la demande future

3. **Outils de Visualisation Recommand√©s**
   - **Streamlit** : Dashboards Python interactifs (gratuit)
   - **Tableau** : Visualisations professionnelles
   - **PowerBI** : Integration Microsoft native

---

## üìù LIVRABLES ATTENDUS

### Pour le Tronc Commun :
1. **Architecture Snowflake** : Cr√©ation des sch√©mas RAW/STAGING/FINAL
2. **Scripts SQL/DBT** : Tables et transformations document√©es
3. **Documentation** : README avec instructions d'ex√©cution
4. **Analyse** : Rapport sur la qualit√© des donn√©es et KPIs calcul√©s

### Pour les Options Avanc√©es :
5. **Script Python** : Automatisation du chargement des donn√©es (si option choisie)
6. **Orchestration** : Pipeline automatis√© (Airflow/Dagster/GitHub Actions)
7. **DBT Core** : Mod√®les de transformation avec tests et documentation
8. **Dashboard** : Visualisations interactives des KPIs principaux


---

## üìä CRIT√àRES D'√âVALUATION

### Tronc Commun (70% de la note)
- ‚úÖ Chargement complet des donn√©es 2024-2025
- ‚úÖ Architecture RAW/STAGING/FINAL respect√©e
- ‚úÖ Nettoyage des donn√©es efficace
- ‚úÖ Documentation claire et compl√®te
- ‚úÖ Code Python et SQL fonctionnels

### Options Avanc√©es (30% de la note)
- üåü Orchestration automatis√©e
- üåü Transformations DBT Core
- üåü Dashboard de visualisation
- üåü Tests de qualit√© des donn√©es
- üåü Optimisation des performances

---

## üîß TRANSFORMATIONS √Ä IMPL√âMENTER

### üìä Cat√©gorisations N√©cessaires :

#### Distances des Trajets :
- **Courts trajets** : ‚â§ 1 mile (d√©placements locaux)
- **Trajets moyens** : 1-5 miles (trajets urbains typiques)
- **Longs trajets** : 5-10 miles (travers√©e d'arrondissements)
- **Tr√®s longs trajets** : > 10 miles (a√©roports, banlieue)

#### P√©riodes Temporelles :
- **Rush Matinal** : 6h-9h (pic de trafic vers le travail)
- **Journ√©e** : 10h-15h (trafic normal)
- **Rush Soir** : 16h-19h (retour du travail)
- **Soir√©e** : 20h-23h (sorties, restaurants)
- **Nuit** : 0h-5h (trafic r√©duit)

#### Types de Jours :
- **Jours de semaine** : Lundi-Vendredi (patterns professionnels)
- **Weekend** : Samedi-Dimanche (patterns loisirs)

### üßÆ M√©triques Calcul√©es :
- **Dur√©e des trajets** : Temps entre prise en charge et d√©pose
- **Vitesse moyenne** : Distance divis√©e par dur√©e
- **Taux de pourboire** : Pourcentage du pourboire vs tarif de base

---

## üí° CONSEILS ET RESSOURCES

### Outils Recommand√©s :
- **Snowflake** : Essai gratuit 30 jours (400$ de cr√©dits)
- **VS Code** : Avec extensions Python et SQL
- **DBT Core** : Installation via pip (optionnel)
- **GitHub** : Pour versionner votre code

### Ressources Essentielles :

#### üì∫ Tutoriels Vid√©o Recommand√©s :
- [**DBT + Snowflake End-to-End**](https://www.youtube.com/watch?v=l-CpmeTFqoI) - Tutorial complet sur l'int√©gration DBT et Snowflake
- [**DBT Core vs DBT Cloud**](https://www.youtube.com/watch?v=ZbLzOgAMAwk) - Comprendre les diff√©rences et choisir la bonne approche
- [**Airflow + NYC Taxi Data**](https://www.youtube.com/watch?v=OLXkGB7krGo&t=518s) - Pipeline d'orchestration avec Airflow

#### üìñ Articles Techniques :
- [**DBT + Snowflake Guide Pratique**](https://dipikajiandani.medium.com/dbt-snowflake-2831681b67f9) - Configuration et bonnes pratiques
- [**Modern ELT Architecture**](https://mayursurani.medium.com/modern-elt-with-dbt-snowflake-and-aws-building-modular-testable-and-governed-data-pipeline-cda2616ad96a) - Architecture compl√®te avec gouvernance des donn√©es

#### üìö Documentation Officielle :
- [Documentation Snowflake](https://docs.snowflake.com)
- [NYC TLC Data Dictionary](https://www.nyc.gov/assets/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf)
- [DBT Core Docs](https://docs.getdbt.com)
- [Airflow Documentation](https://airflow.apache.org/docs/)

### Types d'Analyses √† Impl√©menter :

#### üîç Analyses de Volume :
- **Top 10 des zones de d√©part** : Identifier les zones les plus populaires pour les prises en charge
- **√âvolution mensuelle** : Suivre les tendances du nombre de trajets dans le temps
- **Distribution horaire** : Comprendre les pics de demande selon l'heure de la journ√©e

#### üí∞ Analyses Financi√®res :
- **Revenus par jour de la semaine** : Comparer la rentabilit√© entre semaine et weekend
- **Analyse des pourboires** : √âtudier les patterns de pourboires selon le type de paiement
- **Rentabilit√© par zone** : Identifier les zones les plus lucratives

#### üöó Analyses Op√©rationnelles :
- **Vitesse moyenne par p√©riode** : Analyser la fluidit√© du trafic selon les heures
- **Distance moyenne des trajets** : Comprendre les patterns de mobilit√©
- **Temps d'attente estim√©s** : Calculer les dur√©es moyennes par zone

---

## üéØ R√âSULTATS ATTENDUS

### √Ä la fin des 3 jours, vous devez avoir :

1. **Un Data Warehouse fonctionnel** avec 3 sch√©mas (RAW, STAGING, FINAL)
2. **Minimum 12 mois de donn√©es** charg√©es et nettoy√©es (ann√©e 2024 compl√®te)
3. **Au minimum 3 tables d'analyse** dans le sch√©ma FINAL
4. **Documentation README** avec instructions d'ex√©cution

### KPIs √† calculer (minimum) :
- Nombre total de trajets par mois
- Revenu moyen par trajet
- Distance moyenne parcourue
- Top 10 des zones les plus populaires
- Analyse des heures de pointe

---

## üéì CONCLUSION

Ce projet vous permettra de :
- ‚úÖ Ma√Ætriser l'architecture d'un data warehouse moderne
- ‚úÖ G√©rer des volumes de donn√©es r√©els (plusieurs GB)
- ‚úÖ Appliquer les bonnes pratiques de data engineering
- ‚úÖ Cr√©er un portfolio professionnel avec un projet concret

**Bon courage et n'h√©sitez pas √† poser des questions !**